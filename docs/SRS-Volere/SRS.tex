% THIS DOCUMENT IS FOLLOWS THE VOLERE TEMPLATE BY Suzanne Robertson and James Robertson
% ONLY THE SECTION HEADINGS ARE PROVIDED
%
% Initial draft from https://github.com/Dieblich/volere
%
% Risks are removed because they are covered by the Hazard Analysis
\documentclass[11pt]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx} 
\usepackage{longtable}
\usepackage{geometry}
\usepackage{ltablex}
\usepackage{amssymb}
\usepackage{amsmath}

\keepXColumns

\hypersetup{
    bookmarks=true,         % show bookmarks bar?
      colorlinks=true,      % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=green,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}

\geometry{a4paper, margin=1in}

\newcommand{\lips}{\textit{Insert your content here.}}

\input{../Comments}
\input{../Common}

\begin{document}

\title{Software Requirements Specification for VoiceBridge: An Accessible Speech-to-Control System} 
\author{\authname}
\date{\today}
	
\maketitle

~\newpage

\pagenumbering{arabic}

\tableofcontents

~\newpage

\section*{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\textbf{Date}} & {\textbf{Version}} & {\textbf{Notes}}\\
\midrule
October 2, 2025 & Rawan and Luna & Filled-In Initial Draft of SRS Document\\
October 10, 2025 & Rawan and Luna & Completed SRS Document\\
October 10, 2025 & Mazen and Kelvin & Reviewed and Edited SRS Document\\
November 3, 2025 & Luna & Addressed SRS Glossary TA and Peer Feedback, added customer to glossary for clarity, minor glossary organization improvements\\
December 19, 2025 & Rawan & Addressing peer feedback on caregivers as stakeholders, and addition of C5 and FR6\\
December 19, 2025 & Rawan & Addressing TA feedback: adding section descriptions, figure/table descriptions, and clarification to varying TA questions, removing duplicate constraint (C1), UML description, and other minor fixes\\
\bottomrule
\caption{Revision History for SRS Document}
\end{tabularx}

~\\

~\newpage
\section{Purpose of the Project}
This section describes the overall goals and intended outcomes of the project. It describes the opportunities for developing the project as well as the value it provides for individual users and overall community. 
\subsection{User Business}
 
Individuals with speech impairments face significant barriers when interacting with digital devices. VoiceBridge addresses this gap by providing an accurate, inclusive, and accessible speech-to-control system that enables users to communicate with their devices using their speech, regardless of clarity of articulation. A detailed description of the VoiceBridge problem statement may be references in the \href{https://github.com/speech-buddies/VoiceBridge/blob/main/docs/ProblemStatementAndGoals/ProblemStatement.pdf}{Problem Statement \& Goals document}. \\

\noindent Building on familiar technology, such as personal computers and mobile devices, may be one of the most cost-effective and easily adoptable approaches for improving an individual with disability’s autonomy and access to the world around them. The rise of Automatic Speech Recognition (ASR)  technology and Artificial Intelligence (AI) integrations in the industry provides a novel landscape of opportunities to improve accessibility interfaces. VoiceBridge exploits bleeding-edge technology for a practical and impactful application.

\subsection{Goals of the Project}

\begin{table}[H]
\label{tab:project-goals}
\centering
\setcounter{table}{0}
\begin{tabularx}{\textwidth}{p{1cm}p{4cm}p{8cm}X}
\toprule {\textbf{ID}} & {\textbf{Goal}} & {\textbf{Description}}\\
\midrule
G1 & \textbf{Accurate Speech Transcription} & Reliably convert impaired or slurred speech into text. \\ \hline
G2 & \textbf{Command Mapping} & Translate recognized speech into actionable browser commands. \\ \hline
G3 & \textbf{User Independence} & Enable users with speech impairments to browse autonomously. \\ \hline
G4 & \textbf{Lightweight \& Accessible Design} & Keep the system simple, fast, and cost-effective. \\ \hline
G5 & \textbf{Cross-Browser Compatibility} & Support major browsers (e.g., Chrome, Edge, Firefox). \\ \hline
G6 & \textbf{Robust Error Handling} & Detect and recover gracefully from common failures. \\ \hline
G7 & \textbf{Data Privacy \& Security} & Protect user data and ensure secure local processing. \\ \hline
G8 & \textbf{Customizable Interface} & Allow users to adjust sensitivity, shortcuts, and feedback modes. \\ \hline
G9 & \textbf{Scalable Architecture} & Design the system for future integration beyond browsers. \\ 
\bottomrule
\end{tabularx}
\caption{Project Goals for VoiceBridge: Identifies and describes the overarching goals of VoiceBridge}
\end{table}


\section{Stakeholders}
This section describes VoiceBridge Stakeholders, assigns priorities to them, and defines their respective goals.
\subsection{Client}
The primary client for the VoiceBridge project is the organization or individual funding or commissioning the system. The client is primarily concerned with achieving the following goals: \textbf{\hyperref[tab:project-goals]{G1}}, \textbf{\hyperref[tab:project-goals]{G5}}, and \textbf{\hyperref[tab:project-goals]{G9}}, ensuring accurate speech transcription, cross-browser compatibility, and scalable architecture.

\subsection{Customer \& Hands-On Users of the Project}

The primary customers are also the users of the project, them being individuals with speech impairments, who seek independence and autonomy through technology. Their needs directly relate to: \textbf{\hyperref[tab:project-goals]{G1}}, \textbf{\hyperref[tab:project-goals]{G2}}, \textbf{\hyperref[tab:project-goals]{G3}}, and \textbf{\hyperref[tab:project-goals]{G8}}.

\subsection{Other Stakeholders}
Secondary stakeholders include experts in linguistics, speech processing, and healthcare domains:
\begin{itemize}
    \item Relatives and caregivers of the hands on user of the VoiceBridge Platform.
    \item Speech researchers and linguistics specialists, including the project supervisor, Dr. Christian Brodbeck, who provide insight toward \textbf{\hyperref[tab:project-goals]{G1}}, \textbf{\hyperref[tab:project-goals]{G6}}, and \textbf{\hyperref[tab:project-goals]{G9}}.
    \item Healthcare professionals and speech therapists who advise on usability and accessibility, contributing to \textbf{\hyperref[tab:project-goals]{G3}} and \textbf{\hyperref[tab:project-goals]{G8}}.
    \item Accessibility advocates and organizations interested in promoting the application, aligned with \textbf{\hyperref[tab:project-goals]{G4}} and \textbf{\hyperref[tab:project-goals]{G5}}.
    \item Software developers who implement and maintain the system, supporting \textbf{\hyperref[tab:project-goals]{G9}} and \textbf{\hyperref[tab:project-goals]{G6}}.
\end{itemize}

Tertiary stakeholders include caregivers and professionals who interact with end users, supporting \textbf{\hyperref[tab:project-goals]{G3}} and \textbf{\hyperref[tab:project-goals]{G7}}.

\subsection{Personas}

Potential end users of VoiceBridge include:
\begin{itemize}
    \item \textbf{Amira}, a 45-year-old with Parkinson’s disease, uses the system to log into Gmail and send emails. Her voice is described by speech pathologists as being monopitch and breathy, often making it difficult for her to be understood by the people and technology she interacts with
    \item \textbf{David}, a stroke survivor, uses the system to browse the web and make purchases. His voice is described by pathologists as having slurred and distorted consonants, as well as being monopitch, distorting his speech. 
\end{itemize}


\subsection{Priorities Assigned to Users}

The highest priorities are assigned to end users with speech impairments, as their experience with the system defines its success. Secondary priorities include caregivers and technical experts who support the end users in using and maintaining the system.

\subsection{User Participation}

Individuals matching the target user profiles will be recruited for prototype testing and personalization development. Their participation directly supports refining goals \textbf{\hyperref[tab:project-goals]{G1}}, \textbf{\hyperref[tab:project-goals]{G2}}, \textbf{\hyperref[tab:project-goals]{G3}}, and \textbf{\hyperref[tab:project-goals]{G8}}.

\subsection{Maintenance Users and Service Technicians}
\textbf{Maintenance Users:}\\
\hrule
\begin{itemize}
    \item \textbf{Role:} End-users or caregivers performing basic troubleshooting and initiating support requests.
    \item \textbf{Responsibilities:} 
        \begin{itemize}
            \item Reporting errors or unexpected system behavior (\textbf{\hyperref[tab:project-goals]{G6}}).
            \item Installing application updates (\textbf{\hyperref[tab:project-goals]{G9}}).
            \item Managing user-specific configurations (\textbf{\hyperref[tab:project-goals]{G8}}).
        \end{itemize}
\end{itemize}
\vspace{1em}
\textbf{Service Technicians:}\\
\hrule
\begin{itemize}
    \item \textbf{Role:} Trained technical staff with deeper access to system logs and back-end services.
    \item \textbf{Responsibilities:}
        \begin{itemize}
            \item Investigating reported issues (\textbf{\hyperref[tab:project-goals]{G6}}).
            \item Ensuring transcription accuracy (\textbf{\hyperref[tab:project-goals]{G1}}).
            \item Deploying updates and patches (\textbf{\hyperref[tab:project-goals]{G9}}).
            \item Ensuring compatibility with operating systems and accessibility frameworks (\textbf{\hyperref[tab:project-goals]{G5}}).
            \item Performing preventive maintenance, including performance monitoring and optimization (\textbf{\hyperref[tab:project-goals]{G1}}, \textbf{\hyperref[tab:project-goals]{G6}}).
        \end{itemize}
\end{itemize}
\subsection{Society}

Society is recognized as an essential stakeholder in the VoiceBridge project, given the system’s potential impact on accessibility, inclusion, and digital independence for individuals with speech impairments. The project directly supports broader social goals of equity and participation by enabling users to interact with technology without barriers, contributing to fair access to digital communication and online services.
\\\\
\textbf{Health and Safety:} 
VoiceBridge promotes safe technology use by minimizing physical strain associated with traditional input methods, such as typing or clicking, which can be challenging for users with motor limitations. Data privacy and security protocols safeguard user health information and prevent psychological stress caused by data misuse or breaches, aligning with ethical design standards for assistive technology.
\\\\
\textbf{Cultural and Ethical Considerations:} 
The system is designed to accommodate diverse speech patterns, dialects, and accents, ensuring that cultural and linguistic differences are respected rather than penalized by the model. VoiceBridge avoids stigmatizing language or error messaging, instead emphasizing supportive feedback to maintain user confidence and dignity.
\\\\
\textbf{Social Impact:} 
By reducing communication barriers, VoiceBridge fosters greater inclusion in workplaces, education, and online communities. The system thus contributes to both individual empowerment and collective social benefit.

\section{Mandated Constraints}
This section outlines the external and internal constraints that the system must comply with. It includes environmental constraints, budgetary limits, and implementation restrictions that may impact design decisions, system behavior, or deployment.

\subsection{Solution Constraints}

\noindent\textbf{C1 — The product shall accept non-deterministic user input in the form of natural language speech.}\\
\textbf{Rationale:} Individuals with speech impairments may produce varied speech patterns that cannot be handled by rigid or deterministic command structures.\\
\textbf{Fit Criterion:} The system must be capable of processing and responding to variable natural language inputs without requiring a fixed set of commands.
\par\noindent\rule{\textwidth}{0.4pt}

\noindent\textbf{C2 — The product shall integrate with a browser control application to execute voice-based commands.}\\
\textbf{Rationale:} Browser interaction is a primary accessibility point for most digital services, and browser control is essential for practical use of the system.\\
\textbf{Fit Criterion:} The system must successfully perform browser actions (e.g., opening tabs, navigating to URLs, scrolling) through the integrated control application.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Implementation Environment of the Current System}

\noindent\textbf{C3 — The product will operate within a consumer computing environment consisting of personal computers equipped with microphones.}\\
\textbf{Rationale:} This setup reflects the most common user hardware configuration, ensuring the solution is accessible without additional devices.\\
\textbf{Fit Criterion:} All core functionalities must operate correctly on standard personal computers with a functioning audio input device.
\par\noindent\rule{\textwidth}{0.4pt}

\noindent\textbf{C4 — The application must operate within standard browser security models and cannot bypass AV or OS-level protections.}\\
\textbf{Rationale:} The user’s antivirus/endpoint protection software may block automated browser actions (e.g., script injection, simulated clicks, extensions).\\
\textbf{Fit Criterion:} Full functionality depends on the browser and security software allowing the extension/tool to run.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Partner or Collaborative Applications}

\noindent\textbf{C5 — The initial integration target is Browser Use, an open-source browser control and automation application.}\\
\textbf{Rationale:} Leveraging existing open-source browser automation tools accelerates development and reduces implementation complexity.\\
\textbf{Fit Criterion:} The system must demonstrate the ability to execute at least three browser actions through the integrated partner application during testing.
\par\noindent\rule{\textwidth}{0.4pt}

\noindent\textbf{C6 — Future integrations may include API servers, mobile device agents, and home assistants to extend accessibility and functionality.}\\
\textbf{Rationale:} Ensuring extensibility allows the system to grow and adapt to new platforms or user needs.\\
\textbf{Fit Criterion:} The system architecture must allow seamless integration with additional partner applications without major redesign.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Off-the-Shelf Software}

\noindent\textbf{C7 — The product will rely on off-the-shelf software components, specifically Browser Use for automation and Project Euphonia for voice recording.}\\
\textbf{Rationale:} Using established open-source components allows focus on core functionality, improves maintainability, and supports experimentation with real-world data.\\
\textbf{Fit Criterion:} These components must be successfully integrated into the development workflow, and collected recordings must be stored and processed for model training without licensing conflicts.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Anticipated Workplace Environment}

\noindent\textbf{C8 — The product may be used at home, in public spaces, or in clinical settings, each with varying background noise conditions.}\\
\textbf{Rationale:} The product must function effectively across diverse real-world environments to meet accessibility goals.\\
\textbf{Fit Criterion:} The speech recognition system must maintain acceptable accuracy and responsiveness across all three identified environments during testing.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Schedule Constraints}

\noindent\textbf{C9 — Proof of concept must be completed by November 17, 2025. MVP must be ready within eight months, by May 2026.}\\
\textbf{Rationale:} Deadlines align with capstone project milestones and funding timelines, ensuring timely testing and delivery.\\
\textbf{Fit Criterion:} All proof of concept requirements must be met by the November deadline, and MVP functionality must be fully operational by May 2026.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Budget Constraints}

\noindent\textbf{C10 — The project must operate within the capstone budget allocated for compute infrastructure and development resources.}\\
\textbf{Rationale:} Budget limitations require prioritizing open-source solutions and efficient resource allocation.\\
\textbf{Fit Criterion:} Total cost of infrastructure, hosting, and third-party services must not exceed the allocated capstone budget of \$125 CAD, provided by the supervising institution, McMaster University.
\par\noindent\rule{\textwidth}{0.4pt}


\subsection{Enterprise Constraints}

\noindent\textbf{C11 — The product must comply with all relevant accessibility and privacy regulations, including data usage and user privacy agreements.}\\
\textbf{Rationale:} Compliance protects user rights, upholds institutional standards, and avoids legal or ethical issues.\\
\textbf{Fit Criterion:} All data collection and processing workflows must undergo compliance review, and accessibility features must align with recognized standards (e.g., WCAG).
\par\noindent\rule{\textwidth}{0.4pt}


\section{Naming Conventions and Terminology}
\section*{Glossary of Terms and Acronyms}

\subsection*{General Project Terms}

\begin{description}
  \item[Client] Group or individual funding or commissioning the system, typically the organization requesting the software.
  \item[Customer] An individual or organization that purchases, subscribes to, or deploys the VoiceBridge system for use by end users. Customers may not directly participate in defining requirements but represent those who adopt or distribute the final product.
  \item[End User] Someone who directly uses the system to assist with speech or browser tasks.
  \item[Persona] Example character representing a user to demonstrate design needs, such as Amira with Parkinson’s or David after a stroke.
  \item[Requirement Phase-In] The process of introducing requirements in planned stages, from proof-of-concept to full deployment.
  \item[Stakeholder] Any individual or group involved in or affected by the project, including users, caregivers, technical experts, and funding organizations.
  \item[VoiceBridge] A software system that enables users with speech impairments to control browsers and devices using their voice, even if their speech is slurred or hard to understand. It is the technology whose requirements are described in this document.
\end{description}

\subsection*{Technical Terminology}

\begin{description}
  \item[API (Application Programming Interface)] A set of rules allowing one software program to communicate, exchange services or data with another.
  \item[ASR (Automatic Speech Recognition)] Technology that listens to speech and automatically converts it into written text.
  \item[Browser Agent] Software/code that helps automate browser control tasks.
  \item[CLI (Command Line Interface)] An interaction method using typed text to control a computer, usually for advanced settings.
  \item[JSON (JavaScript Object Notation)] A simple data format both easy for humans and computers to read and write.
  \item[LLM (Large Language Model)] Advanced AI designed for understanding and generating human language.
  \item[Microphone Input] Audio signal collected from a user’s microphone for speech processing.
  \item[MVP (Minimum Viable Product)] Basic version of software with enough features for user testing before further development.
  \item[PoC (Proof of Concept)] A small system built to demonstrate that the main idea works in practice.
  \item[STT (Speech To Text)] Another term for ASR, representing the conversion of speech into text.
  \item[Session] The time period when a user is actively interacting with the system, such as from login to logout.
  \item[TTS (Text To Speech)] Technology that transforms written text into spoken words using a computer-generated voice.
  \item[UML (Unified Modeling Language)] Visual diagram style to represent system structure/workflow, mainly for programmers.
  \item[UUID (Universally Unique Identifier)] Special ID assigned to sessions or user interactions for clear data tracking.
\end{description}

\subsection*{Medical Terminology}

\begin{description}
  \item[Aphasia] Medical condition causing difficulties in communication, affecting speaking, writing, and understanding language.
  \item[ALS (Amyotrophic Lateral Sclerosis)] Nervous system disease affecting movement, including speech, due to muscle weakness.
  \item[Dysarthria] Speech disorder resulting in slurred/slow speech because of nervous system damage.
  \item[Parkinson’s Disease] Progressive neurological disorder affecting movement and speech, often causing tremors and slurred speech.
  \item[Monopitch] Limited variation in pitch; voice sounding flat, often linked to dysarthria. 
  \item[Breathy] Incomplete vocal fold closure can cause breathiness during speech. 
\end{description}

\subsection*{Accessibility and Compliance}

\begin{description}
  \item[Accessibility] Creating software everyone can use, including those with disabilities (e.g., clear text, screen reader support).
  \item[PIPEDA (Personal Information Protection and Electronic Documents Act)] Canadian law regulating personal data collection, use, and protection.
  \item[WCAG (Web Content Accessibility Guidelines)] Guidelines for making web content usable for people with disabilities; “Level AA” meets many key needs.
\end{description}

\subsection*{System Features and Components}

\begin{description}
  \item[Audit Logging] Recording system actions/events to track problems or security issues.
  \item[Command Mapping] System’s ability to recognize and map transcribed text to actions (e.g., “open Gmail”).
  \item[Data Encryption] Protecting information by converting it into unreadable code except for authorized parties.
  \item[Error Handling] Detecting, reporting, and recovering from mistakes or unexpected situations.
  \item[Latency] Time between user speech input and system response.
  \item[Personalization] Adjusting system behavior to match each user’s preferences, speech pattern, or needs.
  \item[Robustness/Fault-Tolerance] Ability to keep working even with errors, noise, or network issues.
  \item[Scalability] Ability for a system to support more users or new features over time.
  \item[Transcription Accuracy] How correctly speech is transformed into text; higher accuracy means fewer mistakes.
\end{description}

\subsection*{Browser and Platform Terms}

\begin{description}
  \item[Browser Control Application] Tool for users to control browsers with voice commands.
  \item[Cross-Browser Compatibility] Ability for software to work across different browsers (Chrome, Edge, Firefox, etc.).
  \item[Device Command] Instruction sent to a computer to perform a task, such as opening applications or typing.
  \item[Off-the-Shelf Software] Ready-made software/components integrated into the project instead of building from scratch.
\end{description}

\subsection*{Miscellaneous Terms}

\begin{description}
  \item[Data Dictionary] Documentation listing information types used by the system, with explanations.
  \item[Feedback Message] Confirmation or notification shown to users, indicating actions or errors.
  \item[Intent] The underlying meaning or goal of what the user says, interpreted by the system.
  \item[Training Data] Audio recordings and transcripts used to improve speech recognition accuracy.
  \item[User Profile] Data associated with each user, like preferences and speech patterns, for personalized command recognition.
\end{description}

\subsection*{Acronym  Reference Table}


Table~\ref{tab:acronyms} provides a consolidated list of all acronyms used throughout this document.


\begin{table}[ht]
\centering
\begin{tabular}{|l|l|p{7cm}|}
\hline
\textbf{Acronym} & \textbf{Full Term} & \textbf{Simple Description} \\
\hline
ALS     & Amyotrophic Lateral Sclerosis          & Disease causing muscle movement problems. \\
API     & Application Programming Interface      & Rules for different software to work together. \\
ASR     & Automatic Speech Recognition           & Converts spoken words into text automatically. \\
BUC     & Business Use Case         & Description of a scenario representing how a business or organization will use the system. \\
CER     & Character Error Rate      & Metric for evaluating speech recognition accuracy at the character level, useful for fine-grained analysis. \\
CLI     & Command Line Interface                 & Computer control by typing commands. \\
FAQ     & Frequently Asked Questions             & Common questions and answers list. \\
JSON    & JavaScript Object Notation             & Easy data format for computers and humans. \\
LLM     & Large Language Model                   & Advanced AI for understanding language. \\
MVP     & Minimum Viable Product                 & First usable version with basic features. \\
PIPEDA  & Personal Info Protection Document Act  & Canadian privacy protection law. \\
PoC     & Proof of Concept                       & A small-scale early prototype. \\
STT     & Speech To Text                        & Converts speech into written text. \\
TTS     & Text To Speech                        & Converts text to computer-generated spoken words. \\
UML     & Unified Modeling Language              & Visual diagrams for system planning. \\
UUID    & Universally Unique Identifier          & Special ID for sessions or users. \\
WCAG    & Web Content Accessibility Guidelines   & Rules for making web sites accessible. \\
WER     & Word Error Rate           & Metric for evaluating the accuracy of speech recognition by comparing transcribed words to the reference text. \\

\hline
\end{tabular}
\caption{Acronym Quick Reference: A table defining the acronyms used in the VoiceBridge SRS document.}
\label{tab:acronyms}
\end{table}

\section{Relevant Facts And Assumptions}

This section presents key facts about the users, environment, and operational context, along with the assumptions that guide system design. It includes user-centered facts, business rules, and design assumptions that influence functionality, usability, and system behavior. These elements ensure that the requirements are grounded in real-world conditions and support the intended goals of the system.
\subsection{Relevant Facts}


\begin{table}[H]
\centering
\setcounter{table}{3}  

\begin{tabularx}{\textwidth}{p{1cm}p{6cm}X}
\toprule {\textbf{Fact ID}} & {\textbf{Fact}} & {\textbf{Explanation / Relevance}}\\
\midrule
F1 & \textbf{Users experience speech impairments of varying severity.} & VoiceBridge must handle varying speech clarity, from slurred to partially formed words (related to (\textbf{\hyperref[tab:project-goals]{G1}}), (\textbf{\hyperref[tab:project-goals]{G2}})). \\ \hline
F2 & \textbf{Users want to communicate and navigate independently.} & Motivates autonomy in using the system without reliance on caretakers (supports (\textbf{\hyperref[tab:project-goals]{G3}})). \\ \hline
F3 & \textbf{Users may have limited mobility.} & Hands-free operation improves accessibility and inclusion (supports (\textbf{\hyperref[tab:project-goals]{G3}}), (\textbf{\hyperref[tab:project-goals]{G4}})). \\ \hline
F4 & \textbf{Users value simplicity and low cognitive load.} & Commands should remain intuitive and easy to use (supports (\textbf{\hyperref[tab:project-goals]{G4}})). \\ \hline
F5 & \textbf{Users may have emotional sensitivity around speech difficulty.} & Interface should be respectful and encouraging without repeating goals (complements (\textbf{\hyperref[tab:project-goals]{G6}})). \\ \hline
F6 & \textbf{Users expect privacy and dignity.} & Data handling should preserve privacy and transparency (supports (\textbf{\hyperref[tab:project-goals]{G7}})). \\ \hline
F7 & \textbf{Users may use different languages or accents.} & System must accommodate linguistic diversity without bias (relates to (\textbf{\hyperref[tab:project-goals]{G1}}), (\textbf{\hyperref[tab:project-goals]{G8}})). \\ \hline
F8 & \textbf{Users may use assistive tools concurrently.} & VoiceBridge should integrate seamlessly with other accessibility tools (supports (\textbf{\hyperref[tab:project-goals]{G4}}), (\textbf{\hyperref[tab:project-goals]{G8}})). \\ \hline
F9 & \textbf{Users will vary in technical comfort.} & Onboarding should be minimal and low-friction (supports (\textbf{\hyperref[tab:project-goals]{G4}}), (\textbf{\hyperref[tab:project-goals]{G8}})). \\ \hline
F10 & \textbf{Users appreciate visual feedback and control.} & Feedback builds trust and reduces frustration (complements (\textbf{\hyperref[tab:project-goals]{G1}}), (\textbf{\hyperref[tab:project-goals]{G8}})). \\
\bottomrule
\caption{User-Centered Facts for VoiceBridge: This table describes the facts linked to the users condition, expectations, and values relevant to their interactions with VoiceBridge. }
\end{tabularx}
\end{table}



\subsection{Business Rules}

\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{p{1cm} X X}
\toprule
\textbf{ID} & \textbf{Business Rule} & \textbf{Rationale} \\
\midrule
BR1 & Users must be able to cancel or stop a command at any time. & Empowers users and prevents frustration. (\hyperref[tab:project-goals]{G3}, \hyperref[tab:project-goals]{G4}) \\
BR2 & Transcribed text must be displayed for user verification before executing critical commands. & Ensures accuracy, avoids misinterpretation, and maintains user confidence, inline with (\hyperref[tab:project-goals]{G1}) \\
BR3 & Browser commands must not execute without user consent for actions with potential data impact (e.g., sending messages, closing tabs). & Protects user privacy and prevents accidental operations. (\hyperref[tab:project-goals]{G2}, \hyperref[tab:project-goals]{G7}) \\
BR4 & The system should provide immediate visual feedback within 5 seconds of speech input. & Builds trust, transparency, and usability for impaired users. (\hyperref[tab:project-goals]{G6}, \hyperref[tab:project-goals]{G1}) \\
BR5 & System must handle moderate background noise without significant degradation of performance. & Maintains reliability in real-world environments.(\hyperref[tab:project-goals]{G1}, \hyperref[tab:project-goals]{G6}) \\
BR6 & Users should be able to configure simple command mappings for personalized tasks. & Supports individual preferences and improves user autonomy. (\hyperref[tab:project-goals]{G2}, \hyperref[tab:project-goals]{G3}, \hyperref[tab:project-goals]{G8}) \\
\bottomrule
\caption{Business Rules for VoiceBridge: This table defines the business rules identified in order to satisfy respective VoiceBridge goals, along with a rationale linking the relevant goal.}
\end{tabularx}
% \label{tab:business-rules}
\end{table}


\subsection{Assumptions}
\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{p{1cm}p{6cm}X}
\toprule {\textbf{ID}} & {\textbf{Assumption}} & {\textbf{Implication for Design}}\\
\midrule
A1 & \textbf{Users have access to a working microphone and modern browser.} & The system assumes functional input hardware and browser APIs for speech capture (see \hyperref[tab:project-goals]{G1}, \hyperref[tab:project-goals]{G5}). \\ \hline
A2 & \textbf{Users will tolerate minor transcription errors if quickly correctable.} & Fast feedback and correction options are more important than perfect accuracy (see \hyperref[tab:project-goals]{G1}, \hyperref[tab:project-goals]{G6}). \\ \hline
A3 & \textbf{Users are willing to train or calibrate the model briefly.} & A short setup phase (e.g., sample phrases) can improve recognition quality (see \hyperref[tab:project-goals]{G1}, \hyperref[tab:project-goals]{G8}). \\ \hline
A4 & \textbf{Users prefer transparent, explainable behavior.} & VoiceBridge should indicate what command is being executed to prevent confusion or mistrust (see \hyperref[tab:project-goals]{G8}). \\ \hline
A5 & \textbf{Users may be in noisy or uncontrolled environments.} & Noise-robust models and confirmation prompts are required to maintain reliability (see \hyperref[tab:project-goals]{G1}, \hyperref[tab:project-goals]{G6}). \\ \hline
A6 & \textbf{Users want emotional ease of use.} & Tone and interface language must feel supportive — e.g., “Let’s try again” instead of “Error” (see \hyperref[tab:project-goals]{G6}). \\ \hline
A7 & \textbf{Users will likely use the tool for daily web tasks.} & The feature set should prioritize essential browser actions (navigation, scrolling, typing, tab control) (see \hyperref[tab:project-goals]{G2}, \hyperref[tab:project-goals]{G3}, \hyperref[tab:project-goals]{G8}). \\
\bottomrule
\caption{Design Assumptions for VoiceBridge: This table defines assumptions imposed on the user's environment/preferences, and the implications of the assumption on the final design}
\end{tabularx}
\end{table}

\section{The Scope of the Work}

This section defines the boundaries and objectives of the VoiceBridge system. It describes the current limitations in browser interaction for users with speech impairments, the context in which the system will operate, and the partitioning of work into functional components. It also specifies the business use cases that guide system functionality from speech input to executed browser commands.
\subsection{The Current Situation}

Individuals with speech impairments currently rely on standard speech-to-text or manual input to use browsers and devices. Existing systems struggle with slurred or atypical speech, often requiring caregiver assistance.

Typical workarounds include typing commands, using alternative inputs, or correcting errors, leading to frustration and limited autonomy.

Current workflow:
User speaks → Standard recognition → Frequent errors → Manual/caregiver correction → Action executed

VoiceBridge aims to replace this with accurate transcription, command mapping, and immediate feedback, enabling independent browser control.

\subsection{The Context of the Work}

\begin{figure}[H]
\centering
\includegraphics[width=1\textwidth]{../imgs/VoiceBridge_context_diagram.png}
\caption{Context Diagram of VoiceBridge: This table defines the interfaces that interact within and external to the VoiceBridge System}
\label{fig:voicebridge-context}
\end{figure}

\subsection{Work Partitioning}
\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{X X X X X}
\toprule
\textbf{Event Name} & \textbf{Input} & \textbf{Output} & \textbf{Brief BUC Summary} & \textbf{Relevant Data Classes} \\
\midrule
\textbf{Input Capture} & User speech via microphone & Audio stream to system & Capture speech for processing & Raw audio, timestamp \\
\hline
\textbf{Speech-to-Text Modelling} & Audio stream & Transcribed text & Convert impaired speech to text & Audio data, transcription \\
\hline
\textbf{Intent Confirmation} & Transcribed text & User confirmation & Verify intended command & Text data, confidence score \\
\hline
\textbf{Command Mapping} & Confirmed text & Actionable command & Map text to browser action & Command definitions, user preferences \\
\hline
\textbf{Browser Interaction Layer} & Actionable command & Executed browser action & Perform command in browser & Command data, page context, execution status \\
\bottomrule
\caption{VoiceBridge Events, Inputs, Outputs, and Data Classes}
\end{tabularx}
\end{table}

\subsection{Specifying a Business Use Case (BUC)} 


\begin{table}[H]
\centering
\begin{tabularx}{\textwidth}{p{2cm}p{3cm}X}
\toprule
\textbf{BUC ID} & \textbf{Name} & \textbf{Description} \\
\midrule
BUC-1 & Capture Speech Input & The user initiates a speech session, and the system captures audio from the microphone for ASR processing. \\
\hline
BUC-2 & Transcribe Speech to Text & The system converts captured audio into text through feature extraction and ASR model inference. \\
\hline
BUC-3 & Interpret Intent & The system parses recognized text to determine the user’s intent and prepares a structured intent object. \\
\hline
BUC-4 & Execute Browser Command & The structured intent is mapped to a browser action, executed, and confirmed visually or audibly to the user. \\
\bottomrule
\caption{Business Use Cases (BUCs) for VoiceBridge}
\end{tabularx}
\end{table}


\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{../imgs/BUC1.png}
\caption{BUC-1: Capture Speech Input}
\label{fig:buc1}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{../imgs/BUC2.png}
\caption{BUC-2: Transcribe Speech to Text}
\label{fig:buc2}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../imgs/BUC3.png}
\caption{BUC-3: Interpret Intent}
\label{fig:buc3}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.4\textwidth]{../imgs/BUC4.png}
\caption{BUC-4: Execute Browser Command}
\label{fig:buc4}
\end{figure}

\section{Business Data Model and Data Dictionary}
\subsection{Business Data Model}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{..//imgs/VoiceBridge_uml.png}
    \caption{VoiceBridge UML Diagram. }
    \label{fig:voicebridge-usecase}
\end{figure} 


The UML class diagram in \href{fig:voicebridge-usecase}{Figure 6} models the key data structures and relationships in the VoiceBridge system. It captures how user interactions flow through the system, from speech input to executed browser commands and user feedback.

\begin{itemize}
    \item \textbf{UserProfile:} Stores individual user data, preferences, and speech characteristics.
    \item \textbf{SpeechSession:} Represents a single interaction instance, capturing audio input and derived speech features.
    \item \textbf{Transcription:} Stores the converted text, confidence scores, and status/error codes from speech recognition.
    \item \textbf{UserIntent:} Represents the parsed intent from the transcription, including semantic slots.
    \item \textbf{ExecutableCommand:} Maps the user intent to actionable browser commands with associated parameters.
    \item \textbf{APIRequest:} Represents optional requests generated by commands for external systems.
    \item \textbf{FeedbackMessage:} Logs system responses or messages to the user during the session.
\end{itemize}

\noindent
\textbf{Relationships and Rationale:}
\begin{itemize}
    \item \texttt{UserProfile \& SpeechSession:} Each user may initiate multiple speech sessions. This models user activity over time and allows the system to track session history for personalization and auditing.
    \item \texttt{SpeechSession \& Transcription:} Each session produces a single transcription. This ensures that each audio capture is processed into text for intent interpretation.
    \item \texttt{Transcription \& UserIntent:} Each transcription is parsed into a user intent. This relationship models the mandatory step of interpreting what the user intends to do.
    \item \texttt{UserIntent \& ExecutableCommand:} Each intent maps to a specific browser command. This ensures that interpreted user intentions are actionable within the system.
    \item \texttt{ExecutableCommand \& APIRequest:} Some commands may produce an external API request. This optional relationship models integration with external services when required.
    \item \texttt{SpeechSession \& FeedbackMessage:} Sessions may generate multiple feedback messages, such as transcription confirmations or error alerts, improving transparency and user trust.
    \item \texttt{ExecutableCommand \& FeedbackMessage:} Executed commands may produce multiple messages, such as success notifications or warnings, keeping users informed about system actions.
\end{itemize}


This diagram complements the event and BUC tables by showing how data flows between components and how user interactions are represented in the system’s data model.

\subsection{Data Dictionary}

\begin{table}[H]
\centering
\footnotesize

\begin{tabularx}{\textwidth}{p{3cm} p{4cm} X  X p{4cm}}
\toprule
\textbf{Field} & \textbf{Description} & \textbf{Type} & \textbf{Source} & \textbf{Usage} \\
\midrule
\textbf{Audio\_Input} & Raw speech signal captured from microphone & PCM, WAV, 16 kHz, 16-bit & User microphone & Primary input for ASR processing \\
\hline
\textbf{Speech\_Features} & Extracted acoustic features (e.g., MFCCs, spectrogram) & N-dimensional array & Feature extractor module & Internal representation used by ASR engine \\
\hline
\textbf{Transcript\_Text} & Recognized text output from speech input & UTF-8 encoded free text & ASR engine & Basis for interpreting user intent \\
\hline
\textbf{Error\_Code} & Status or error indicator for system response & Integer & ASR engine / Controller & 0 = Success, >0 = specific error type \\
\hline
\textbf{User\_Profile} & Speaker-specific data such as ID, preferences, and speech patterns & JSON object & User database & Enables personalized recognition and response \\
\hline
\textbf{Timestamp} & Time marker for recognition or command event & DateTime & System clock & Used for logging, debugging, and tracking \\
\hline
\textbf{User\_Intent} & Parsed intent derived from natural language input & JSON (intent and slots) & Interpreter module & Structured meaning representation (e.g., \{“intent”: “open\_file”, “file”: “report.pdf”\}) \\
\hline
\textbf{Exec\_Command} & Structured command before browser execution & JSON object or Abstract Syntax Tree & Interpreter module & Translates user intent into executable browser actions \\
\hline
\textbf{API\_Request} & Outgoing request to external or browser API & REST / GraphQL formatted message & Interpreter module → API translator & Executes command or triggers action in external system \\
\hline
\textbf{Feedback\_Message} & User-facing feedback or error output & String / Audio / JSON & VoiceBridge UI & Confirms action success or requests clarification \\
\hline
\textbf{Session\_ID} & Unique identifier for a single user interaction session & UUID / String & System controller & Links data objects across a single speech-to-command event \\
\bottomrule
\caption{VoiceBridge Data Dictionary}
\end{tabularx}
\end{table}

\section{The Scope of the Product}
\subsection{Product Boundary}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{..//imgs/VoiceBridge_use_case_diagram.png}
    \caption{VoiceBridge Use Case Diagram. Each ellipse represents a Product Use Case (PUC) corresponding to a major system function.}
    \label{fig:voicebridge-usecase}
\end{figure} 
\subsection{Product Use Case Table}
\begin{table}[H]
\centering
\caption{Product Use Case (PUC) Table}
\begin{tabularx}{\textwidth}{p{1.5cm}p{3cm}p{2.5cm}p{3cm}X}
\toprule
\textbf{PUC ID} & \textbf{Event Trigger} & \textbf{Input} & \textbf{Output} & \textbf{Description} \\
\midrule
PUC-1 & User speaks into microphone & Audio signal & Captured speech data & System listens for user speech input. \\
PUC-2 & Speech captured & Speech data & Text transcription & Converts impaired speech to text using trained model. \\
PUC-3 & Transcription complete & Transcribed text & Confirmation prompt / feedback & Seeks user confirmation to ensure correct interpretation. \\
PUC-4 & Intent confirmed & Confirmed command text & Browser command execution & Maps intent to actionable browser function. \\
PUC-5 & Command executed or error & System response & Success or error feedback to user & Provides feedback or prompts retry on failure. \\
\bottomrule
\end{tabularx}
\end{table}

\subsubsection{Individual Product Use Cases (PUC's)}

This section defines the detailed Product Use Cases (PUCs) for the VoiceBridge system. Each PUC describes the interaction between the user and the system, including purpose, actors, triggers, inputs/outputs, and main scenarios.

\subsubsection*{PUC-1: Capture User Speech}
\textbf{Primary Actor:} User \\
\textbf{Trigger:} User begins speaking into the microphone. \\
\textbf{Precondition:} The microphone is connected and permissions are granted. \\
\textbf{Input:} Audio signal (live speech). \\
\textbf{Output:} Captured audio data stream. \\
\textbf{Postcondition:} Audio data is made available for processing by the ASR (Automatic Speech Recognition) module. \\

\textbf{Main Scenario:}
\begin{enumerate}
  \item User activates the VoiceBridge interface (e.g., presses a “Listen” button).
  \item The system listens through the microphone for input.
  \item The system captures the speech signal and stores it temporarily in memory.
  \item Captured data is sent to the speech-to-text module for processing.
\end{enumerate}

\textbf{Alternative Flow:}
\begin{itemize}
  \item If the microphone is unavailable or access is denied, the system displays an error prompt.
  \item User can retry after adjusting permissions or hardware connection.
\end{itemize}

\bigskip

\subsubsection*{PUC-2: Convert Speech to Text}
\textbf{Primary Actor:} System (Speech Recognition Module) \\
\textbf{Trigger:} Audio capture event completed. \\
\textbf{Input:} Captured speech data. \\
\textbf{Output:} Transcribed text. \\
\textbf{Postcondition:} Transcription results are ready for user confirmation. \\

\textbf{Main Scenario:}
\begin{enumerate}
  \item System processes the captured audio stream using a trained ASR model.
  \item Acoustic and linguistic features are extracted.
  \item Speech is converted to text and stored temporarily.
  \item Transcribed text is passed to the confirmation display.
\end{enumerate}

\textbf{Alternative Flow:}
\begin{itemize}
  \item If transcription confidence is below threshold, the system requests a repeat.
\end{itemize}

\bigskip

\subsubsection*{PUC-3: Confirm Transcription}
\textbf{Primary Actor:} User \\
\textbf{Trigger:} System displays transcribed text. \\
\textbf{Input:} Transcribed text. \\
\textbf{Output:} User confirmation or correction. \\

\textbf{Main Scenario:}
\begin{enumerate}
  \item The transcribed text is displayed to the user for verification.
  \item User confirms that the text is correct or requests reprocessing.
  \item System records the confirmation and proceeds to intent mapping.
\end{enumerate}

\textbf{Alternative Flow:}
\begin{itemize}
  \item If user rejects the transcription, the system returns to PUC-1 for re-input.
\end{itemize}

\bigskip

\subsubsection*{PUC-4: Map Intent to Browser Command}
\textbf{Primary Actor:} System (Command Mapping Module) \\
\textbf{Trigger:} User confirmation received. \\
\textbf{Input:} Confirmed command text. \\
\textbf{Output:} Actionable browser command. \\

\textbf{Main Scenario:}
\begin{enumerate}
  \item System parses confirmed text for intent (e.g., “open YouTube”).
  \item System searches for matching browser or OS command.
  \item Mapped command is passed to the execution layer.
\end{enumerate}

\textbf{Alternative Flow:}
\begin{itemize}
  \item If no matching command is found, the system provides suggestions.
\end{itemize}

\bigskip

\subsubsection*{PUC-5: Execute Command and Provide Feedback}
\textbf{Primary Actor:} System \\
\textbf{Trigger:} Actionable command received. \\
\textbf{Input:} Command representation (API or accessibility call). \\
\textbf{Output:} Visible browser or OS action, and feedback message. \\

\textbf{Main Scenario:}
\begin{enumerate}
  \item System executes the command using the browser’s API or accessibility layer.
  \item The target application or tab performs the intended action (e.g., opens a webpage).
  \item System provides visual and/or auditory feedback to confirm success.
\end{enumerate}

\textbf{Alternative Flow:}
\begin{itemize}
  \item If the command execution fails, an error message or retry option is displayed.
\end{itemize}

\bigskip
\section{Undesired Event Handling}
\begin{table}[H]
\centering
\footnotesize
\begin{tabularx}{\textwidth}{p{1cm} p{2cm} X X p{1cm} p{2cm}}
\toprule
\textbf{Event ID} & \textbf{Description} & \textbf{Possible Cause} & \textbf{System Response / Handling Strategy} & \textbf{Severity} & \textbf{User Notification} \\
\midrule
UE-1 & No Speech Detected & User is silent or microphone muted. & System times out after configurable interval (e.g., 5 s) and displays “No input detected. Please speak again.” & Low & Visual and optional audio cue. \\
\hline
UE-2 & Unintelligible Speech / Low Confidence Transcription & Background noise, unclear articulation, or poor model match. & VoiceBridge requests repetition and highlights uncertain words. Logs instance for model improvement. & Medium & On-screen prompt: “Sorry, I didn’t catch that.” \\
\hline
UE-3 & Misinterpreted Command & Incorrect speech-to-text mapping or ambiguous command phrase. & Requires confirmation before executing potentially disruptive browser actions (e.g., closing tab, submitting form). & High & Confirmation dialog: “Did you mean ‘Close tab’?” \\
\hline
UE-4 & Microphone Access Denied & User or OS blocks microphone permission. & System notifies user and provides step-by-step instructions to enable microphone in browser/OS settings. & High & Visual warning banner. \\
\hline
UE-5 & Browser Extension / API Failure & Browser crashes, extension disabled, or interface unresponsive. & Detect failure via heartbeat signal. Attempt reconnection; if unsuccessful, disable commands and show recovery notice. & High & “Browser connection lost — attempting to reconnect.” \\
\hline
UE-6 & Network Connectivity Loss & Internet connection interrupted. & Offline mode activated: local commands (scroll, zoom, etc.) remain functional; external navigation disabled. & Medium & “Network unavailable — limited mode active.” \\
\hline
UE-7 & System Crash / Model Process Failure & Unexpected error during ML inference or memory overflow. & System logs event, restarts inference module, and recovers previous session state when possible. & Critical & “VoiceBridge restarted after an error.” \\
\hline
UE-8 & Data Privacy Breach Attempt & Unauthorized access to stored speech logs or transcripts. & Encrypts all local logs; triggers security alert, terminates unauthorized session, and notifies user. & Critical & “Security alert — your data is protected and the session has been closed.” \\
\hline
UE-9 & Latency Exceeds Threshold & Inference or browser response exceeds acceptable delay (e.g., > 2 s). & Display progress indicator; optionally degrade to simplified model or local processing fallback. & Low & Spinner with “Processing…” message. \\
\hline
UE-10 & User Cancels Ongoing Command & User says “cancel” or “stop.” & Immediately halts current command execution and clears pending queue. & Low & Confirmation sound or text “Cancelled.” \\
\bottomrule
\caption{VoiceBridge User Event Handling Scenarios}
\end{tabularx}
\end{table}



\section{Functional Requirements}

\subsection{FR1: Accept Speech Audio via Microphone}
\textbf{Description:} The system must capture live speech input from the user through a standard built-in or external microphone.\\
\textbf{Rationale:} Speech audio contains frequency components up to approximately 8 kHz. To capture this audio accurately without distortion, the sampling rate must be at least twice the maximum frequency, resulting in a minimum required rate of 16 kHz. This ensures reliable speech transcription and is supported by standard built-in and external microphone hardware.\\
\textbf{Fit Criterion:} The system reliably detects and records audio from default OS microphone devices across Windows, macOS, iOS, and Android, with a minimum 16 kHz sampling rate.

\bigskip
\subsection{FR2: Convert Impaired Speech to Text with greater than or equal to 80\% Accuracy (MVP)}
\textbf{Description:} The system must process the captured audio and output a textual representation of the spoken utterance.\\
\textbf{Rationale:} Accurate transcription is the core functionality that enables communication and command execution. Without acceptable accuracy, the product fails its purpose.\\
\textbf{Fit Criterion:} In evaluation on a test dataset of impaired speech, transcription accuracy must reach at least 80\% Word Error Rate (WER) reduction compared to baseline models, and achieve greater than or equal to 80\% accuracy for common commands.

\bigskip
\subsection{FR3: Display Transcription for Verification}
\textbf{Description:} The transcribed text must be displayed in real time on the user’s device interface.\\
\textbf{Rationale:} Transparent feedback allows the user to verify correctness, catch errors, and build trust in the system.\\
\textbf{Fit Criterion:} Every spoken input is displayed within 2 seconds as text on the UI, with at least 95\% consistency across trials.

\bigskip
\subsection{FR4: Map Text to Arbitrary Device Commands}
\textbf{Description:} The system must recognize when transcribed text corresponds to a predefined device action (e.g., “open amazon.ca,” “draft a new email”) and translate it into the appropriate command representation (API, CLI, or accessibility call).\\
\textbf{Rationale:} Mapping allows the system to extend beyond communication into real device control, empowering user independence.\\
\textbf{Fit Criterion:} For a test set of 50 predefined commands, the system maps user input to the correct command representation in at least 90\% of cases.

\bigskip
\subsection{FR5: Execute Commands on the Host Device}
\textbf{Description:} The system must execute the mapped commands through the host device’s accessibility framework or APIs, resulting in visible user action (e.g., app launch, scrolling, text entry).\\
\textbf{Rationale:} Without execution, the system remains a transcription tool only. Execution closes the loop between speech input and device interaction.\\
\textbf{Fit Criterion:} For each correctly recognized command, the intended system action occurs on the device within 2 seconds, with greater than or equal to 95\% reliability across test scenarios.

\bigskip
\subsection{FR6: Handle Security Software Interference}
\textbf{Description:} The system must detect when browser, operating system, or antivirus security controls block or restrict automated actions and provide clear feedback to the user, including the affected command and available fallback options.\\
\textbf{Rationale:} Security software may prevent automated execution, which could otherwise result in silent failures and unsafe user assumptions about task completion. User awareness preserves safety and usability.\\
\textbf{Fit Criterion:} In test scenarios where automation is blocked, the system correctly detects the restriction and notifies the user in greater than or equal to 95\% of cases within 2 seconds of the failed action.

\section{Look and Feel Requirements}
\subsection{Appearance Requirements}
The interface shall have a clean and minimal design to reduce cognitive load. Key elements should be visually distinct, with consistent spacing, and color usage to support quick recognition of actions.

Since it’s a browser integration, the user interface should minimally interfere with the visibility of the content on the page. The interface should only capture the user’s attention as functionally needed (i.e., listening to user prompts, confirming user intent), but should otherwise blend in with the browser interface.

\subsection{Style Requirements}
The system shall maintain a professional and neutral visual style suitable for general workplace use. Colors, icons, and fonts should prioritize clarity over branding at this stage. Future iterations may incorporate custom styling or theming.


\section{Usability and Humanity Requirements}
\subsection{Ease of Use Requirements}
The system should minimize user effort by providing a simple, intuitive interface. Key actions should be accessible within 3-4 interactions, with clear feedback after each action.
\subsection{Personalization and Internationalization Requirements}
The system should support basic personalization (e.g., remembering user preferences) and allow easy adaptation for different languages or regions at a later stage. For the PoC, English support is sufficient.
\subsection{Learning Requirements}
The system should be learnable within 10 minutes without prior training or documentation. Users should be able to complete core tasks on their first attempt through the interfaces navigation tutorial upon first time launch. Additional documentation should be supplemental but not necessary. 
\subsection{Understandability and Politeness Requirements}
The system should use clear, direct, and neutral language in responses. Error messages or clarifications should remain polite and informative.
\subsection{Accessibility Requirements}
The interface should be navigable using standard assistive tools and offer clear text contrast and legible font sizes. Full accessibility compliance is not required at the PoC stage but should be feasible for future iterations.

\section{Performance Requirements}
\subsection{Speed and Latency Requirements}
Under normal operating conditions, latency requirements can be broken down into:

Speech interpretation: 5 s after end of utterance

Command generation \& execution: 10-15 seconds after end of speech interpretation
\subsection{Safety-Critical Requirements}
The system shall enforce guardrails to prevent unsafe or unintended actions, requiring validation and user confirmation for potentially disruptive operations, and provide warnings or fail-safes for errors.
\subsection{Precision or Accuracy Requirements}
ASR accuracy shall be at least 70\% in stationary noise conditions. The system shall achieve at least 80\% command recognition precision under stationary noise conditions for the PoC.
\subsection{Robustness or Fault-Tolerance Requirements}
The system shall remain stable under fluctuating network conditions and noisy input. Fallback mechanisms (e.g., retry logic, error messaging) shall ensure graceful issue handling.
\subsection{Capacity Requirements}
The system shall support at least 20 concurrent users without service degradation if the product is commercialized.
\subsection{Scalability or Extensibility Requirements}
The system architecture shall allow horizontal scaling to handle increased traffic and modular extensions fo new interaction capabilities. 
\subsection{Longevity Requirements}
The system shall be designed to operate reliably over a minimum of 5 years, with maintainable and updatable components to support long-term product evolution.

\section{Operational and Environmental Requirements}
\subsection{Expected Physical Environment}
The product shall be operable in a variety of typical office, home, or institutional environments where users perform their daily tasks. The system shall be robust to stationary background noise such as air conditioning, computer fans, and ambient hum. It is not required to reliably handle non-stationary noise, including multiple people speaking or sudden loud interruptions. No modifications to the host operating system, browser, or network configuration shall be required.
\subsection{Wider Environment Requirements}
The primary interface shall be web-based, accessible via standard web browsers, to maximize user accessibility and support flexible use cases.
\subsection{Requirements for Interfacing with Adjacent Systems}
\begin{enumerate}
    \item The system shall integrate with existing browser-based platforms and may interface with external language interpreter modules.
    \item Open-source components (e.g., browser interaction agents and libraries) may be incorporated, ensuring compatibility and maintainability.
\end{enumerate}

\subsection{Productization Requirements}
\begin{enumerate}
    \item The product shall be deployable for multiple users within an organization, supporting secure user accounts and personalized ASR profiles.
    \item The design shall allow packaging and distribution without requiring technical setup by end users. The product shall have straightforward installation or access via pre-configured web access and automatic model initialization.
    \item Productization shall include logging suitable for monitoring performance and usage in a hosted environment.
    \item The system shall include mechanisms for updates to features with minimal disruption to users.
\end{enumerate}
\subsection{Release Requirements}
The product shall follow a defined release cycle, providing minor updates quarterly and major updates semi-annually. Each release must maintain backward compatibility with user data, personalization settings, and existing features. Release planning will account for maintenance effort, compute resources, and compliance obligations.

\section{Maintainability and Support Requirements}
\subsection{Maintenance Requirements}
Code must be modular, documented, and testable to support scalability, debugging, and future updates. Maintenance must be possible by developers who were not the original authors. 
\subsection{Supportability Requirements}
The product shall provide an accessible Help Page and a Frequently Asked Questions (FAQ) section with clear instructions. It shall be displayed with high-contrast visuals, simple language, and auditory and visual aids. 
\subsection{Adaptability Requirements}
The system must run on common workplace platforms via a web browser, including Windows 10 or later, macOS 12 Monterey or later, and Linux distributions such as Ubuntu 20.04 LTS or later, supporting modern web browsers.

\section{Security Requirements}
\subsection{Access Requirements}
Only authorized end users shall be able to access personalized ASR features, voice command execution, and saved transcripts. Access shall be role-based:

\begin{itemize}
    \item \textbf{Primary users (end users):} can access their own data.
    \item \textbf{Secondary users (supervisors/SMEs):} may have read-only access to assist with support or troubleshooting.
    \item \textbf{Tertiary users (caregivers):} may have limited access to assist the end user, can view basic usage history and transcripts but cannot modify settings.
\end{itemize}

Access to external services (e.g., LLM APIs) shall be rate-limited to ensure system stability, control costs, and prevent abuse.
\subsection{Integrity Requirements}
The system must provide real-time confirmation and validation of commands before execution to ensure they match user intent. 
\subsection{Privacy Requirements}
The system must gather explicity user consent for storing voice and personal data. All user data used for model improvement must be anonymized. Database and personalized ASR models must maintain integrity through secure, versioned backups. Unauthorized changes or corruption of user data must be prevented. 
\subsection{Audit Requirements}
The system shall maintain secure logs of major actions and commands, including loging events, access to profile and personal data, and command execution failures. Logs shall be protected and retained in a secure database. 
\subsection{Immunity Requirements}
The system must be resilient to accidental misuse. It shall handle noisy input robustly, avoid executing unintended commands, and operate safely within rate limits to prevent resource overload. 

\section{Cultural Requirements}
\subsection{Cultural Requirements}
The system shall maintain a culturally neutral and respectful tone when prompting users, avoiding slang, bias, and discriminatory language. It must include ethical guardrails to prevent the generation of harmful content or execution of potentially dangerous commands.

It shall support inclusive and accessible design to serve users across diverse cultural backgrounds.

\section{Compliance Requirements}
\subsection{Legal Requirements}
The project shall comply with the Personal Information Protection and Electronic Documents Act (PIPEDA) regarding the collection, storage, and handling of personal information.

\subsection{Standards Compliance Requirements}
The application must comply with the Web Content Accessibility Guidelines (WCAG) 2.0, Level AA guidelines to ensure usability by individuals with disabilities.

\section{Requirements Likely and Unlikely to Change}

\subsection{Likely to Change}
\begin{itemize}
    \item \textbf{12.1 Speed \& Latency:} The system shall process speech input and return text in near real-time.\\
    \textit{Rationale:} Performance targets may improve as speech recognition and browser processing capabilities evolve.

    \item \textbf{14.3 Adaptability:} The system shall allow updates for new languages, user preferences, or accessibility features.\\
    \textit{Rationale:} Future user needs or new assistive technologies may require system modifications.

    \item \textbf{11.2 Personalization \& Internationalization:} The system shall support preferred voice, accent handling, and language selection.\\
    \textit{Rationale:} User preferences and supported languages are likely to expand over time.

    \item \textbf{12.6 Scalability \& Extensibility:} The system shall support an increasing number of concurrent users and new modules.\\
    \textit{Rationale:} User growth or additional features may require changes in infrastructure.

    \item \textbf{13.5 Release Requirements:} Updates shall be deployable on web browsers without downtime.\\
    \textit{Rationale:} Deployment strategies may change as development tools or environments evolve.

    \item \textbf{26.2 Personalized ASR Fine-Tuning:} The system shall allow individualized model tuning to improve transcription accuracy.\\
    \textit{Rationale:} Model improvements and user feedback may necessitate adjustments.


    \item \textbf{17.2 Standards Compliance Requirements:} System shall follow relevant industry standards.\\
    \textit{Rationale:} Standard adherence ensures safety, reliability, and credibility. As the product evolves, new features may require compliance with additional standards.
\end{itemize}

\subsection{Unlikely to Change}
\begin{itemize}
    \item \textbf{9.1 Functional Requirements:} The system shall accurately transcribe speech to text for users with speech impairments.\\
    \textit{Rationale:} Core transcription functionality is foundational and will not change.

    \item \textbf{10.1 Appearance:} Interface shall be clean, minimal, and visually organized to reduce cognitive load.\\
    \textit{Rationale:} Minimal and clear design is essential for accessibility and usability.

    \item \textbf{10.2 Style:} Interface shall use consistent fonts, spacing, and colors to support clarity.\\
    \textit{Rationale:} Visual consistency is fundamental for usability.

    \item \textbf{11.1 Ease of Use:} Users shall complete tasks with minimal steps or cognitive effort.\\
    \textit{Rationale:} Streamlined interaction is a core accessibility requirement.

    \item \textbf{15.3 Privacy Requirements:} User data shall be encrypted in the database and logs. \\
    \textit{Rationale:} Privacy protection is legally required and critical for trust, this requirement will not change.

    \item \textbf{17.1 Legal Requirements:} System shall comply with relevant regulations (e.g., PIPEDA).\\
    \textit{Rationale:} Compliance is mandatory for this project, must be complied with at all times.

\end{itemize}

\section{Open Issues}
The primary open issue is maintaining high ASR accuracy across the diverse and severe spectrum of dysarthric speech. This requires extensive training and validation data, as well as careful model tuning.


\section{Off-the-Shelf Solutions}
\subsection{Ready-Made Products}
The project will evaluate existing, specialized speech recognition models and applications (e.g., Whisper model and Project Euphonia) as performance baselines.

\subsection{Reusable Components}
Potential reused components could include existing Text-to-Speech (TTS) modules for feedback and LLMs to map user commands into structured actions.

\subsection{Products That Can Be Copied}
Open-source browser automation agents (e.g., The AI browser agent) may be integrated for command execution via voice input.


\section{New Problems}
\subsection{Effects on the Current Environment}
The product shall operate without modifying the user’s OS, browser, or network configuration. This separation prevents unintended impact from incorrect commands.

\subsection{Effects on the Installed Systems}
The product shall not bypass firewalls, alter security settings, access banned sites, install untrusted content, or perform any malware execution.

\subsection{Potential User Problems}
Due to the non-deterministic nature of dysarthric speech patterns, a user’s exact speech type may not be fully captured by the model, leading to higher training overhead for personalization before the system becomes reliably usable for them. Users may experience misinterpretations requiring retries, which can cause frustration.

\subsection{Limitations in the Anticipated Implementation Environment That May
Inhibit the New Product}
Variability in dysarthric speech may necessitate frequent retraining of ASR models.

Real-time performance varies between devices, depending on processing power and low-latency operation.
\subsection{Follow-Up Problems}
The local operation limits the ability to perform remote problem diagnosis if any issues arise.


\section{Tasks}
\subsection{Project Planning}
Breakdown of major tasks:

Our main tasks are centered on preparing the system by training and tuning the dysarthric ASR model, integrating the core command interpreter, designing the accessible interface, and conducting rigorous testing.
\subsection{Planning of the Development Phases}
A detailed schedule of development phases, milestones, and dependencies is outlined in the PoC and Development Plan.

\section{Migration to the New Product}
\subsection{Requirements for Migration to the New Product}
The system shall support new users with no prior ASR and interpreter experience through an onboarding process. 

The system shall support transitioning users migrating from an existing system by allowing for easy uploading of recordings of their speech training data.

\subsection{Data That Has to be Modified or Translated for the New System}
All previous transcripts, audio files, and personalization data shall be tied to secure user accounts.

Users shall be able to access their data from any supported device after logging in and authentication.

\section{Costs}
The primary costs for this product are related to machine learning computation and hosting. Development and training will initially leverage Compute Canada credits provided by the supervising research team, along with Colab Pro (CAD 13.99/month).

No external hosting costs are anticipated for the initial release; however, optional hosting may be required for commercial distribution and deployments. If hosting is included, approximate costs for cloud-based deployment on Google Cloud Platform (GCP) include: training and inference on GPUs (~\$50 CAD/month for pilot use), storage (~\$3 CAD/month), and minimal networking (~\$2–5 CAD/month). Costs scale with the number of users and training frequency. All estimates are approximate and intended for planning purposes.
\section{User Documentation and Training}
\subsection{User Documentation Requirements}
The system shall provide clear, accessible documentation, including an instructional guide and FAQ. (As noted in Section 14b, supporting requirements already cover this in detail.)

\subsection{Training Requirements}
Training shall not require formal instruction; the documentation and interface shall support self-directed onboarding.

\section{Waiting Room}
The system shall display launch, loading, or processing pages during transitions to provide users with clear feedback and reduce confusion during waiting periods.

\section{Ideas for Solution}

\subsection{Browser-Based Extensions}
The product is primarily web-based. Future considerations could include desktop or mobile apps to broaden the scope and accessibility (see Section 13 for environment and interface requirements).

\subsection{Personalized ASR Fine-Tuning}
Consider incremental model tuning paired with real-time streaming of speech input. This could be an approach to adapt to individual speech patterns while minimizing the training time overhead, related to the adaptability requirements discussed in earlier sections.

\subsection{LLM Command Mapping}
User intent parsing via context-aware LLMs could improve natural language command interpretation, as mentioned in Section 13.

\subsection{Noise Filtering}
Beyond stationary noise, adaptive filtering techniques could be adapted to enhance recognition in busier environments. Section 13 already specifies stationary noise handling.

\subsection{Open-Source Integrations}
Potential use of browser automation or voice control frameworks can be investigated, as mentioned in Section 16 for off-the-shelf solutions.

\subsection{Accessibility Enhancements}
Additional visual, auditory, or haptic cues for feedback and help features could enhance usability. Section 14 highlights basic supportability requirements that these enhancements would build on.

\subsection{Data Encryption}
Anonymized logging and privacy approaches can balance model improvement with privacy in mind. Section 15 discusses privacy requirements in detail.

\section{Requirements Phase-In Plan}

The following plan outlines the order in which the system requirements (9.1--17.2) will be addressed, aligned with project phases. Prioritization ensures that core functional requirements and critical non-functional requirements are validated first, with refinements and extensions added in later phases. Timelines for each phase are detailed in the Development Plan.

\subsection{Phase Definitions}

\begin{itemize}
    \item \textbf{Proof of Concept (PoC):} Validate feasibility of core functionality and critical performance metrics.
    \item \textbf{Revision 0:} Expand functionality, address usability, accessibility, and integrate initial security/privacy mechanisms.
    \item \textbf{Revision 1:} Final refinement, full productization, compliance, cultural, and maintainability requirements.
\end{itemize}

\subsection{Requirements Phase-In}

\begin{enumerate}
    % Functional Requirements
    \item \textbf{9.1 Functional Requirements:} Core system behaviors including input processing and basic transcription.\\
    \textit{Phase: PoC} \\
    \textit{Rationale:} Core functionality must be demonstrated to validate feasibility.

    % Look and Feel
    \item \textbf{10.1 Appearance Requirements:} Initial UI layout and interface elements.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Visual interface can be refined after core functions are stable.

    \item \textbf{10.2 Style Requirements:} Consistent fonts, colors, and spacing.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Enhances readability and user experience once functionality is proven.

    % Usability
    \item \textbf{11.1 Ease of Use Requirements:} Interface must be intuitive and straightforward.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Important for usability testing, applied after functional PoC is complete.

    \item \textbf{11.2 Personalization and Internationalization Requirements:} Language/voice adaptations.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Applied later when system is functionally stable.

    \item \textbf{11.3 Learning Requirements:} System should adapt to repeated user patterns.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Machine learning or adaptation features require validated data pipelines.

    \item \textbf{11.4 Understandability and Politeness Requirements:} Feedback should be clear and respectful.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Improves user experience during early testing.

    \item \textbf{11.5 Accessibility Requirements:} Interface supports assistive technologies.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Early implementation ensures PoC testing is inclusive.

    % Performance
    \item \textbf{12.1 Speed and Latency Requirements:} System responds within acceptable time frames.\\
    \textit{Phase: PoC} \\
    \textit{Rationale:} Performance validation is crucial for feasibility.

    \item \textbf{12.2 Safety-Critical Requirements:} Ensure no harmful outputs or behaviors.\\
    \textit{Phase: PoC} \\
    \textit{Rationale:} Early validation prevents critical errors in PoC.

    \item \textbf{12.3 Precision or Accuracy Requirements:} Transcription must meet minimum WER/CER.\\
    \textit{Phase: PoC} \\
    \textit{Rationale:} Accuracy is the central PoC metric.

    \item \textbf{12.4 Robustness or Fault-Tolerance Requirements:} Handle errors gracefully.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Necessary for reliable system use beyond PoC.

    \item \textbf{12.5 Capacity Requirements:} Support a small set of concurrent users/data.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Ensure system can handle expected early usage.

    \item \textbf{12.6 Scalability or Extensibility Requirements:} System should allow future growth.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Added after functional validation for longer-term planning.

    \item \textbf{12.7 Longevity Requirements:} Components maintainable over time.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Stability and maintainability are late-stage concerns.

    % Operational & Environment
    \item \textbf{13.1 Expected Physical Environment:} System works on typical office/lab computers.\\
    \textit{Phase: PoC} \\
    \textit{Rationale:} Early testing on target devices is essential.

    \item \textbf{13.2 Wider Environment Requirements:} Browser compatibility.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Once core functionality works, broaden environment testing.

    \item \textbf{13.3 Requirements for Interfacing with Adjacent Systems:} Integration points identified.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} External integration is late-phase after internal systems are stable.

    \item \textbf{13.4 Productization Requirements:} Ready for deployment.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Combines all prior validations for release.

    \item \textbf{13.5 Release Requirements:} Packaging, distribution readiness.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Ensures final delivery meets standards.

    % Maintainability & Support
    \item \textbf{14.1 Maintenance Requirements:} System maintainable.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Implemented once core system is functional.

    \item \textbf{14.2 Supportability Requirements:} Technical support procedures.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Late-stage requirement after main functionality.

    \item \textbf{14.3 Adaptability Requirements:} System can be upgraded.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Flexibility comes after base system is validated.

    % Security
    \item \textbf{15.1 Access Requirements:} User roles and permissions.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Early implementation secures initial PoC data.

    \item \textbf{15.2 Integrity Requirements:} Prevent tampering or corruption.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Ensures reliable data handling.

    \item \textbf{15.3 Privacy Requirements:} Encrypt data in transit and at rest.\\
    \textit{Phase: Revision 0} \\
    \textit{Rationale:} Essential for user trust and legal compliance.

    \item \textbf{15.4 Audit Requirements:} Track critical system events.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Auditing implemented after basic functionality and privacy are validated.

    \item \textbf{15.5 Immunity Requirements:} Protection from external attacks.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Security hardening is a late-stage activity.

    % Cultural & Compliance
    \item \textbf{16.1 Cultural Requirements:} Respect cultural norms and sensitivities.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Applied after all functional, UI, and content elements are stable.

    \item \textbf{17.1 Legal Requirements:} Comply with laws and regulations.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Legal compliance verified after security, privacy, and functionality are validated.

    \item \textbf{17.2 Standards Compliance Requirements:} Follow industry standards.\\
    \textit{Phase: Revision 1} \\
    \textit{Rationale:} Ensures credibility and certification readiness at final stage.
\end{enumerate}
\subsection{Requirement Implementation Timeline}

The phasing of requirements for VoiceBridge follows a structured, incremental schedule aligned with prototype maturity and evaluation cycles. The table below summarizes the planned order and target completion dates for each phase.

\begin{table}[h!]
\centering
\begin{tabular}{p{3cm}p{4cm}p{7cm}}
\toprule
\textbf{Phase} & \textbf{Target Date} & \textbf{Focus and Included Requirements} \\
\midrule
\textbf{Proof of Concept (PoC)} & October--November 2025 &
Implement core functionality: speech input capture, transcription (FR9.1, 12.1–12.3, 13.1), and safety validation (12.2). Establish baseline latency, accuracy, and system feasibility. \\

\textbf{Revision 0} & December 2025--January 2026 &
Integrate user interface, accessibility, and initial security layers. Includes appearance (10.1–10.2), usability (11.1, 11.4–11.5), robustness (12.4–12.5), and privacy/integrity controls (15.1–15.3). Conduct early user testing. \\

\textbf{Revision 1} & February--April 2026 &
Expand system capability and compliance. Add personalization (11.2–11.3), scalability (12.6–12.7), interoperability (13.3–13.5), supportability (14.1–14.3), advanced security (15.4–15.5), and cultural/legal alignment (16.1, 17.1–17.2). Prepare for deployment. \\
\bottomrule
\end{tabular}
\label{tab:req-timeline}
\end{table}

\noindent This phased plan ensures that feasibility and safety are validated early (PoC), usability and inclusivity are developed next (Revision 0), and full scalability, compliance, and maintainability are achieved in the final iteration (Revision 1).




\section{Formal Specification}

This section provides a simplified formal model of the VoiceBridge system using a state-based representation.  
The goal is to describe how the system transitions between major states during operation.

\subsection{System States}

Let the system have the following states:

\[
Q = \{Idle, Listening, Processing, Confirming, Executing, Error\}
\]

The system starts in the \textit{Idle} state and reacts to user or system inputs.

\subsection{Inputs and Transitions}

Inputs to the system are represented as:

\[
\Sigma = \{Start, AudioInput, Confirm, Reject, Execute, Fail\}
\]

The transition function $\delta(q, \sigma)$ describes how the system changes state:

\[
\begin{array}{ll}
\delta(Idle, Start) = Listening \\
\delta(Listening, AudioInput) = Processing \\
\delta(Processing, Confirm) = Executing \\
\delta(Processing, Reject) = Listening \\
\delta(Executing, Execute) = Idle \\
\delta(Executing, Fail) = Error
\end{array}
\]

\subsection{Output Behavior}

Each state produces a specific output:

\[
\begin{array}{ll}
Idle \rightarrow \text{System ready prompt} \\
Listening \rightarrow \text{Microphone active} \\
Processing \rightarrow \text{Speech to text conversion} \\
Confirming \rightarrow \text{User verification message} \\
Executing \rightarrow \text{Command execution feedback} \\
Error \rightarrow \text{Error or retry prompt}
\end{array}
\]

\subsection{Mapping to Requirements}

This formal model represents the main workflow of VoiceBridge and aligns with the following functional requirements:

\begin{itemize}
    \item FR1: Accept Speech Input ($Idle \rightarrow Listening$)
    \item FR2: Convert Speech to Text ($Listening \rightarrow Processing$)
    \item FR3: Confirm Transcription ($Processing \rightarrow Confirming$)
    \item FR4: Map Intent to Command ($Confirming \rightarrow Executing$)
    \item FR5: Execute Command ($Executing \rightarrow Idle$)
\end{itemize}

This simplified formalization shows how user input moves through each stage of the system in a predictable, testable way, ensuring clarity and correctness of behavior.




\newpage{}
\section*{Appendix --- Reflection}

\input{../Reflection.tex}

\input{../SRS_Reflection.tex}

\end{document}